---
title: "Conservation from smoothed betas"
author: "ks"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, message=FALSE}
library(GenomicRanges)
library(data.table)
library(ggplot2)
library(patchwork)
library(rtracklayer)
library(dplyr)
library(GenomeInfoDb)
library(BSgenome.Hsapiens.UCSC.hg38)
```

### Background

Darryl suggested generating a BED file of 1Mb region (1 million bases) around conserved sites (avg PWD < 0.1).  Analysis will be prototyped using chromosome 17, picked for containing TP53.
There are ~1.08x10^6 CpG sites in chr17. 

Here's some methods others have applied to the analysis of WGBS data. Sample beta value estimates are smoothed by pooling m,u read counts in 500 bp intervals (NAR 2015 'DSS-single' paper). I will do this and add the filter of requiring a minimum of 5 reads to retain the estimate. Ben Berman defines methylated-prone regions (in CIMP cancer) by computing mean DNAm in 5 adjacent CpGs on chromosome 4 (~1470693 CpGs) and finds PMDs from 20-kb windows. I will want to apply a threshold for the minimum number of adjacent estimates to define an interval. I use 4, but we might want to increase this. 

Earlier analysis of Darryl's data shows Tumor M has the lowest average DNA methylation (0.54), suggesting the tumor might have the widest distribution of conservation. Tumor H would be another to try (mean DNAm = 0.57). EN has highest coverage (median 23) compared to JN, IN (median 15, 13, respectively). A quick look at sequencing depth of the Y chromosomes suggests JN, IN are female and EN is male.

Once I identify conserved regions in tumor and in normal tissue, I will want to compare them to each other. Because some tumors have higher sequencing depth than normal samples JN, IN, I will require that the tumor and normal are measured on the same CpG sites before calling conserved regions.  Samples are processed individually and CpGs are merged for comparisons of PWDs before calling intervals. 

I will search for conservation in windows of 4+ CpGs, > 200bps, CpG PWD (for smoothed beta) < 0.1. Smoothed beta values on ends of chromosome are kept if we have more than 5 reads regardless of whether interval only has data from 1/2 the intervals.

```{r data-files, cache=TRUE}
readdir <- c("~kims/Google Drive/My Drive/Data/hpc-archive/wg_bed/bed_files")
samplename <- c("MA","MB","IN","JN")
```


```{r get-list, echo=FALSE}
# Load the exclusion list file (for hg38, as an example)
# starting here https://github.com/Boyle-Lab/Blacklist?tab=readme-ov-file takes me
# https://www.encodeproject.org/annotations/ENCSR636HFF/
# and download https://www.encodeproject.org/files/ENCFF356LFX/
excludelist <- import("data/ENCFF356LFX.bed.gz")
```

```{r summarize-each-file, echo=FALSE}
read_bedfile <- 
      function(sample = "MA") {
          fin <- fread(file.path(readdir,paste0(sample,".bed")))
  
          setnames(fin, c("chr","start","end","beta","depth","m","u"))
          # filter on assembly
          desired_chromosomes <- paste0("chr",c(as.character(1:22),"X","Y"))
          fin <- fin[chr %in% desired_chromosomes]
          # filter on exclude list
  
          betav <- GRanges(seqnames = fin$chr,
                            IRanges(start = fin$start,end = fin$end))
          values(betav) <- DataFrame(m = fin$m, depth = fin$depth)

          s1 <- subsetByOverlaps(betav, excludelist, invert = TRUE)
          s1  
      }

calc_smoothed_beta <- 
  function(gr, chr="chr17", window_size = 500) {
      # Convert GRanges to data.table
       s1 <- as.data.table(gr)
       s1 <- s1[seqnames==chr]
       s1[, row_id := .I]
     

      half_window <- window_size / 2
      # Expand each interval by 250 bp in both directions
      s1[, `:=`(
           smooth_start = start - half_window,
             smooth_end = end + half_window
       )]
       # Create a copy for overlap comparison
      s1_overlap <- copy(s1)
      # Set keys for fast overlap join
      setkey(s1_overlap, seqnames, start, end)

      # Perform a self-join to find overlaps within the smoothed window
      hits <- foverlaps(
          s1[, .(row_id, seqnames, start = smooth_start, end = smooth_end)],
          s1_overlap[, .(row_id_match = row_id, seqnames, start, end, m, depth)],
          by.x = c("seqnames", "start", "end"),
          by.y = c("seqnames", "start", "end"),
          type = "any",
          nomatch = 0
      )

      # Now for each original row, compute total m and total depth from overlapping intervals
      rm(s1_overlap)
      smoothed_scores <- hits[, .(m_tot     = sum(m, na.rm = TRUE),
                                  depth_tot = sum(depth,na.rm=TRUE) ), by = row_id]

      # Merge smoothed scores back to original
      s1 <- merge(s1, smoothed_scores, by = "row_id", all.x = TRUE, sort = FALSE)
      table(s1$depth_tot>4)

      s1 <- s1[depth_tot > 4]
      s1$smoothed_beta <- s1$m_tot/s1$depth_tot
      s1
}

combine_paired_samples <- function (s1,s2, chr = thischr, window_size = 500) {
#  s1 <- "IA"
#  s2 <- "IB"
#  chr <- "chr18"
#  window_size <- 500
  
        s1.gr <- read_bedfile(sample=s1)
        s1_smoothed_beta <- calc_smoothed_beta(s1.gr,chr=chr,window_size=window_size)
 
        s2.gr <- read_bedfile(sample=s2)
        s2_smoothed_beta <- calc_smoothed_beta(s2.gr,chr=chr,window_size=window_size)

        setkey(s1_smoothed_beta, seqnames, start, end)
        setkey(s2_smoothed_beta, seqnames, start, end)
        
        dt <- merge(
                s1_smoothed_beta[, .(seqnames, start, end, s1.smoothed_beta = smoothed_beta, s1.depth_tot = depth_tot)],
                s2_smoothed_beta[, .(seqnames, start, end, s2.smoothed_beta = smoothed_beta, s2.depth_tot = depth_tot)],
                by.x = c("seqnames", "start", "end"),
                by.y = c("seqnames", "start", "end")
              )
        
        rm(s1.gr,s2.gr)
        
        dt$pwd      = abs(dt$s1.smoothed_beta - dt$s2.smoothed_beta)
        dt$avgdepth_tot = dt$s1.depth_tot + dt$s2.depth_tot
        dt$s12diff  = dt$s1.smoothed_beta - dt$s2.smoothed_beta
        dt$avgb     = (dt$s1.smoothed_beta + dt$s2.smoothed_beta)/2
        dt
}
```



```{r get-list-of-datatables-with-smoothed-pwd}
pickchr <- "chr17"

nn.pairs.lst <- list(
  c("JN","IN"),
  c("JN","EN"),
  c("IN","EN")
)

tumor.pairs.lst <- list(
  c("MA","MB"),
  c("HA","HB")
)
```

```{r process, echo=FALSE}
nn.dt_list <- list()
for (i in 1:length(nn.pairs.lst)) {
          pair <- nn.pairs.lst[[i]]
          pair 
          nn.dt_list[[i]] <- combine_paired_samples(pair[1],
                                                    pair[2], chr=pickchr, 
                                                    window_size = 500)
}
names(nn.dt_list) <- c("JN_v_IN","JN_v_EN","IN_v_EN")

tumor.dt_list <- list()
for (i in 1:length(tumor.pairs.lst)) {
          pair <- tumor.pairs.lst[[i]]
          pair 
          tumor.dt_list[[i]] <- combine_paired_samples(pair[1],
                                                       pair[2], chr=pickchr, 
                                                    window_size = 500)
}
names(tumor.dt_list) <- c("MA_v_MB","HA_v_HB")

```

The number of PWD measures for paired samples:
```{r ncpgs}
lapply(nn.dt_list,nrow)
lapply(tumor.dt_list,nrow)
```


```{r merge-dts-before-interval-detection, echo=FALSE}
# merge paired samples
dtc <- merge(
            tumor.dt_list[[1]][, .(seqnames, start, end, 
                            pair1.pwd  = pwd,
                            pair1.avgdepth_tot = avgdepth_tot,
                            pair1.diff = s12diff,
                            pair1.avgb = avgb)],
            nn.dt_list[[1]][, .(seqnames, start, end, 
                                 pair2.pwd  = pwd, 
                                 pair2.avgdepth_tot = avgdepth_tot,
                                 pair2.diff = s12diff,
                                 pair2.avgb = avgb)],

            by.x = c("seqnames", "start", "end"),
            by.y = c("seqnames", "start", "end")
            )
       
ndt <- names(dtc)  
ndt <- sub("pair1",names(tumor.dt_list[1]),ndt)
ndt <- sub("pair2",   names(nn.dt_list[1]),ndt)
names(dtc) <- ndt
```

There are `r nrow(dtc)` CpGs measured in each paired sample.

### Data visualizations

```{r density-plots, echo=FALSE}
p1 <- ggplot(dtc, aes(x = JN_v_IN.avgb)) +
  geom_density(fill = "skyblue", alpha = 0.5) +
  labs(
    title = "Non-tumor colon (JN,IN)",
    x = "Average (smoothed) Beta value",
    y = "Density"
  ) +
  theme_minimal()

p2 <- ggplot(dtc, aes(x = MA_v_MB.avgb)) +
          geom_density(fill = "skyblue", alpha = 0.5) +
          labs(
            title = "Tumor M (n=2 samples)",
            x = "Average (smoothed) Beta value",
            y = "Density"
          ) +
        theme_minimal()

p1 + p2
```

Plot all pwds
```{r pwds, echo=FALSE}
tumor.dtcomb <- rbindlist(tumor.dt_list, idcol = "source")
nn.dtcomb <- rbindlist(nn.dt_list, idcol = "source")
dtcomb <- rbind(tumor.dtcomb,nn.dtcomb)
rm(tumor.dtcomb,nn.dtcomb)
```
  
```{r}
pv <- ggplot(dtcomb, aes(x=source, y = pwd, fill = source)) +
       geom_violin() +
  # violin plot with median points
        stat_summary(fun=median, geom="point", shape=23, size=2) +
        ylim(0,.5) 
pv + geom_hline(yintercept = 0.05, linetype = "dashed")
```


## Plots along genomic coordinates (Normal & Tumor M only)

```{r browser-view-pmd, echo=FALSE}
p1 <- ggplot(dtc[5001:10000], aes(x = start, y = JN_v_IN.avgb)) +
  geom_point(alpha = 0.5, size = 0.7) +
  labs(
    title = "Normal Tissue (JN,IN)",
    x = "Genomic Position",
    y = "smoothed Beta"
  ) +
  theme_minimal()

p2 <- ggplot(dtc[5001:10000], aes(x = start, y = JN_v_IN.pwd)) +
  geom_point(alpha = 0.5, size = 0.7) +
  geom_smooth(method = "gam") +
  labs(
    title = "Normal Tissue (JN,IN)",
    x = "Genomic Position",
    y = "PWD"
  ) + ylim(0,0.45) +
  theme_minimal()


p3 <- ggplot(dtc[5001:10000], aes(x = start, y = MA_v_MB.avgb)) +
  geom_point(alpha = 0.5, size = 0.7) +
  #geom_smooth(method = "gam") +
  labs(
    title = "Tumor (MA,MB)",
    x = "Genomic Position",
    y = "smoothed Beta"
  ) +
  theme_minimal()

p4<- ggplot(dtc[5001:10000], aes(x = start, y = MA_v_MB.pwd)) +
  geom_point(alpha = 0.5, size = 0.7) +
  geom_smooth(method = "gam") +
  labs(
    title = "Tumor (MA,MB)",
    x = "Genomic Position",
    y = "PWD"
  ) + ylim(0,0.45) +
  theme_minimal()
```

```{r, echo=FALSE}
((p1 | p2) / (p3 | p4))
```

That's cool. The right side looks like a partially methylated domain. Is the DNAm conserved?
The left side of the figure shows more conservation than the right side for tumor M.

### Region containing TP53

```{r browser-view-p53, echo=FALSE}
p1 <- ggplot(dtc[125001:130000], aes(x = start, y = JN_v_IN.avgb)) +
  geom_point(alpha = 0.5, size = 0.7) +
  labs(
    title = "Normal Tissue (JN,IN)",
    x = "Genomic Position",
    y = "smoothed Beta"
  ) + 
  theme_minimal() + geom_segment(aes(x = 7661779, xend = 7687538, y = -0.02, yend = -0.02),
                                 color = "red", linewidth = 1.3)

p2 <- ggplot(dtc[125001:130000], aes(x = start, y = JN_v_IN.pwd)) +
  geom_point(alpha = 0.5, size = 0.7) +
  geom_smooth(method = "gam") +
  labs(
    title = "Normal Tissue (JN,IN)",
    x = "Genomic Position",
    y = "PWD"
  ) + ylim(-0.02,0.65) +
  theme_minimal() + geom_segment(aes(x = 7661779, xend = 7687538, y = -0.02, yend = -0.02),
                                 color = "red", linewidth = 1.3)


p3 <- ggplot(dtc[125001:130000], aes(x = start, y = MA_v_MB.avgb)) +
  geom_point(alpha = 0.5, size = 0.7) +
  #geom_smooth(method = "gam") +
  labs(
    title = "Tumor (MA,MB)",
    x = "Genomic Position",
    y = "smoothed Beta"
  ) +
  theme_minimal() + geom_segment(aes(x = 7661779, xend = 7687538, y = -0.02, yend = -0.02),
                                 color = "red", linewidth = 1.3)

p4<- ggplot(dtc[125001:130000], aes(x = start, y = MA_v_MB.pwd)) +
  geom_point(alpha = 0.5, size = 0.7) +
  geom_smooth(method = "gam") +
  labs(
    title = "Tumor (MA,MB)",
    x = "Genomic Position",
    y = "PWD"
  ) + ylim(-0.02,0.65) +
  theme_minimal() + geom_segment(aes(x = 7661779, xend = 7687538, y = -0.02, yend = -0.02),
                                 color = "red", linewidth = 1.3)
```

```{r, echo=FALSE, warning=FALSE}
((p1 | p2) / (p3 | p4)) 
```

TP53 is marked in red: 7,661,779-7,687,538 (25,760 bp)


## Define Conserved Regions

The smoothed betas have been estimated using all CpGs in a window of 500 bps and requiring a depth of 5+ reads from that interval, so they are more stable than beta values from single CpGs. Let's look at the distribution of PWD from the smoothed beta values and pick a cutoff for defining conservation. 

Tumor M PWD:
```{r}
summary(dtc$MA_v_MB.pwd)
```


Normal J,I PWD:
```{r summarize}
summary(dtc$JN_v_IN.pwd)
```
The within tumor PWD is less than the between normal PWD.

Definition of conserved region:  
1. (smoothed) CpG PWD < 0.1   
2. 4+ neighboring conserved CpGs  
3. minimum width 201 bps

I also tried using the median PWD in normal tissue to define conservation. This is more stringent than the 0.05 cutoff we've used in the past and yielded another ~5000 intervals. The increase in number of intervals can happen by having multiple shorter intervals of high conservation nested in a larger conserved region defined by the looser PWD cutoff.


```{r define-intervals, echo=FALSE}
find_Intervals_of_conserv <- function(dtc,ncg=4, minwidth=200, pwd = "MA_v_MB.pwd",
                                      pwd.consv.cutoff = 0.1){
    dtc$consv <- ifelse(dtc[, ..pwd] < pwd.consv.cutoff,1,0)

    # compute run-lengths of 1/0s
    Mc <- rle(dtc$consv)
    # assign unique IDs to the different intervals
    intID <- rep(1:length(Mc$values), Mc$lengths)
    # if the values are 0, assign ID name 0
    intID <- intID * dtc$consv
    # count number of CpGs per interval
    tc <- table(intID)
    
    print(paste("Number of intervals:",length(tc)))
    print("Distribution of num CpGs per interval:")
    print(summary(as.vector(tc[-1]))) #exclude count for intID=0 (1st element of vector)
    
    # get the intID for intervals with fewer than ncg and assign ID 0
    print("Require minimum 4 CpGs per interval")
    shortint <- names(tc)[tc<ncg]
    intIDf <- ifelse(is.element(intID,shortint),0,intID)
    dtc$intIDf <- intIDf
    
    # subset to conserved CpGs (those with positive ID numbers)
    # get bed file format of conserved regions
    dtcf.sum <- dtc[intIDf > 0 , .(start = min(start),
                                   end   = max(end),
                                 AvB.pwd = mean(get(pwd), na.rm=T),
                                   n_CpG = .N), by = .(intIDf, seqnames)]
    # add widths 
    dtcf.sum$width <- dtcf.sum$end-dtcf.sum$start
    # summarize interval widths
    print("Interval widths")
    print(summary(dtcf.sum$width))
    # requires intervals have minimum minwidth bps 
    print(paste("require minimum width of",minwidth))
    dtcf.sum <- dtcf.sum[ width > minwidth, ]
    print(paste("Number of intervals remaining:",nrow(dtcf.sum)))
    print(paste("# intervals/ original # CpGs:",round(nrow(dtcf.sum)/nrow(dtc),3)))
    dtcf.sum
}
```

### Tumor M
```{r consv-intervals}
TumorM.dt<- find_Intervals_of_conserv(dtc,pwd = "MA_v_MB.pwd")
```
There are still a lot of intervals to study using this definition. Should I require they be longer than 200 bps?

Let's find the interval with the most CpGs.
```{r mostCpGs}
TumorM.dt[ n_CpG == max(n_CpG),]
```

Now let's find the widest interval.
```{r widest}
TumorM.dt[ width == max(width),]
```

## Plot (smoothed) Beta Values for conserved regions


```{r data, echo=FALSE}
MA.gr <- read_bedfile("MA")
MA.dt <- calc_smoothed_beta(MA.gr, chr="chr17", window_size = 500)
MB.gr <- read_bedfile("MB")
MB.dt <- calc_smoothed_beta(MB.gr, chr="chr17", window_size = 500)
rm(MA.gr,MB.gr)

IN.gr <- read_bedfile("IN")
IN.dt <- calc_smoothed_beta(IN.gr, chr="chr17", window_size = 500)
JN.gr <- read_bedfile("JN")
JN.dt <- calc_smoothed_beta(JN.gr, chr="chr17", window_size = 500)
rm(IN.gr,JN.gr)
```


Handpick intervals to see the differences in conservation.

```{r plot-region, echo=FALSE}
plot_region <- function(pos1=81510412, posn = 81515609) {
      sMA <- MA.dt[MA.dt$start > (pos1 - 1) & MA.dt$end < (posn + 1),]
      sMB <- MB.dt[MB.dt$start > (pos1 - 1) & MB.dt$end < (posn + 1),]
      sIN <- IN.dt[IN.dt$start > (pos1 - 1) & IN.dt$end < (posn + 1),]
      sJN <- JN.dt[JN.dt$start > (pos1 - 1) & JN.dt$end < (posn + 1),]
      sMA$sample <- "MA"
      sMB$sample <- "MB"
      sIN$sample <- "IN"
      sJN$sample <- "JN"
      long.df <- rbind.data.frame(sMA,sMB,sIN,sJN)
      long.df$sample <- as.factor(long.df$sample)
      
      ggplot(data=long.df, aes(x=start, y=smoothed_beta, group = sample, color = sample)) +
          geom_line() + 
          geom_point()
}
```


Plot the region with the most CpGs.
```{r plot1-region1}
plot_region(pos1 = 48609950, posn = 48650197	)
```

This data looks good.

What about the very long region of just 8 CpGs?

```{r plot-region2}
plot_region(pos1 = 36175775, posn = 36586344)
```

This looks like some irregular sequencing data.  How many such intervals are there (wide with few CpGs)?  Apply cluster analysis to identify outlier intervals that are extremely wide and omit them.
```{r filter-outliers}
p1 <- ggplot(TumorM.dt, aes( x = n_CpG, y = width)) +
    geom_point()

set.seed(30)
kmgps <- stats::kmeans(TumorM.dt[,.(n_CpG,width)],centers=2,nstart = 200)
gp <- factor(kmgps$cluster)
p2 <- ggplot(TumorM.dt, aes( x = n_CpG, y = width, color = gp)) +
    geom_point()

clustertokeep <- which(kmgps$size==max(kmgps$size)) 
TumorM.dt <- TumorM.dt[kmgps$cluster==clustertokeep,]
p3<- ggplot(TumorM.dt, aes( x = n_CpG, y = width)) +
    geom_point()

TumorM.dt <- TumorM.dt[width < 50000,]
p4<- ggplot(TumorM.dt, aes( x = n_CpG, y = width)) +
    geom_point()

(p1 + p2)/(p3 + p4)
```

It's hard to know if the clusters near 50000 bps in width are problematic. If I re-cluster again, it filters more aggressively and will drop the interval with the most CpGs and I already visually inspected that one and decided the data are good quality. I will filter on 50kb here to retain the interval with the largest number of CpGs (bottom left figure). 

Let's find intervals conserved in Normal (tidy them), and then identify Tumor M intervals that overlap Normal intervals vs distinct.

### Normal-Normal (JN,IN)
```{r consv-intervals-nn}
nn.dt<- find_Intervals_of_conserv(dtc,pwd = "JN_v_IN.pwd")
```

```{r mostCpGs-nn}
nn.dt[ n_CpG == max(n_CpG),]
```

Plot the region with the most CpGs.
```{r plot1-region2}
plot_region(pos1 = 82014514, posn = 82032430)
```

Yes, this interval does appear very conserved in normal tissue.

Let's repeat the analysis performed on tumor M to identify outlier intervals to drop from analysis.
```{r}
p1 <- ggplot(nn.dt, aes( x = n_CpG, y = width)) +
      geom_point()

set.seed(30)
kmgps <- stats::kmeans(nn.dt[,.(n_CpG,width)],centers=2,nstart = 200)
gp <- factor(kmgps$cluster)
p2 <- ggplot(nn.dt, aes( x = n_CpG, y = width, color = gp)) +
    geom_point()

clustertokeep <- which(kmgps$size==max(kmgps$size)) 
nn.dt <- nn.dt[kmgps$cluster==clustertokeep,]
p3 <- ggplot(nn.dt, aes( x = n_CpG, y = width)) +
    geom_point()

(p1+p2)/p3
```

Should I add another filter? Re-clustering does not pick more outliers, but splits the intervals into 2 groups. If I require >9 CpGs (instead of 4+), I can drop 25\% of intervals (~20,000 remaining).  I'll be focusing on the large intervals later, making this decision irrelevant.

## Overlap conserved intervals: Tumor M  &  JN-IN (normal) 

```{r overlap, echo=FALSE}
TumorM.gr <- GRanges(seqnames=TumorM.dt$seqnames,
                     IRanges(start = TumorM.dt$start,end = TumorM.dt$end))
values(TumorM.gr) <- DataFrame(id = TumorM.dt$intIDf,
                                apwd = TumorM.dt$AvB.pwd,
                                ncpg = TumorM.dt$n_CpG)


nn.gr <- GRanges(seqnames=nn.dt$seqnames,
                     IRanges(start = nn.dt$start,end = nn.dt$end))
values(nn.gr) <- DataFrame(id = nn.dt$intIDf,
                                apwd = nn.dt$AvB.pwd,
                                ncpg = nn.dt$n_CpG)
```

```{r}
TumorMonly <- subsetByOverlaps(TumorM.gr, nn.gr, invert = TRUE)
commonRegions <- subsetByOverlaps(TumorM.gr, nn.gr)
```

Specifically Tumor M intervals: `r length(TumorMonly)`.  
Distribution of widths: `r summary(width(TumorMonly))`

Tumor M & Normal overlapped intervals: `r length(commonRegions)`
Distribution of widths: `r summary(width(commonRegions))`

Very Few intervals are Tumor M specific.  Let's add this information back to our scatterplot and pick an interval that is tumor M specific.
```{r}
common_idxM <- findOverlaps(TumorM.gr, nn.gr)
idxMonly <- ifelse(!is.element(1:nrow(TumorM.dt),queryHits(common_idxM)),1,0)
ggplot(TumorM.dt, aes( x = n_CpG, y = width)) +
    geom_point() + facet_wrap( ~ factor(idxMonly))
```

```{r}
TumorM.dt[idxMonly ==1 & n_CpG >100]
```

```{r plot1-region4}
p1 <- plot_region(pos1 = 48549520, posn = 48553578)
p2 <- plot_region(pos1 = 48581771	, posn = 48584931)
p3 <- plot_region(pos1 = 81118265, posn = 81120542)

(p1 + p2)/p3
```

That figure on the bottom is interesting!

### Distances between intervals

What are distances between intervals? 

```{r}
summary(distance(TumorMonly[-length(TumorMonly)], TumorMonly[-1]))
summary(distance(commonRegions[-length(commonRegions)], commonRegions[-1]))
```
Some are pretty darn close to each other so I could combine nearby intervals. Then I have to decide how close should they be to combine them? Instead, since I'm going to increase the interval to a 1 Mb region, I think I'll just keep these as they are, and see how many of these intervals are covered by the 1 Mb regions I select.

## Pick Top Conserved Intervals

Let me pick the interval with the most CpGs, and see how many other intervals are covered if I expand the width to 1Mb.
```{r}
si <- seqinfo(BSgenome.Hsapiens.UCSC.hg38)
# region with max nCpG
maxncpg_idx <- which(values(commonRegions)$ncpg == max(values(commonRegions)$ncpg))
gr <- commonRegions[maxncpg_idx]
gr_big <- resize(gr, 1000000, fix = "center")

# clip to chromosome bounds
seqlevels(gr_big) <- seqlevels(si)   # align seqlevels
seqlengths(gr_big) <- seqlengths(si)
gr_big <- trim(gr_big)

sum(countOverlaps(commonRegions,gr_big))
```

Here is a picture of which intervals were covered by the 1 Mb region. Only 1 of the intervals with lots of CpGs, and then smaller intervals.
```{r plot-covered-intervals, echo=FALSE}
overlap_int <- countOverlaps(commonRegions, gr_big)
cR.dt <- as.data.table(values(commonRegions))
cR.dt$width <- width(commonRegions)
ggplot(cR.dt, aes( x = ncpg, y = width)) +
    geom_point() + 
    ggtitle("Conserved Intervals covered by 1 Mb region (1=Yes, 0 = No)") +
    facet_wrap( ~ factor(overlap_int))
```

Now take the intervals with more than 500 CpGs, expand them, and see if any of the intervals overlap each other.
```{r, warning=FALSE}
gr <- commonRegions[values(commonRegions)$ncpg > 500]

gr_big <- resize(gr, 1000000, fix = "center")
# clip to chromosome bounds
seqlevels(gr_big) <- seqlevels(si)   # align seqlevels
seqlengths(gr_big) <- seqlengths(si)
gr_big <- trim(gr_big)
```

`r length(gr)` intervals have more than 500 CpGs.

What is the average PWD for these 40 intervals? All have a minimum 500 CpGs.
```{r }
summary(values(gr)$apwd)
```


```{r}
reduce_big <- reduce(gr_big)
reduce_big
width(reduce_big)
```

Nice. Write this to a file.
```{r}
rtracklayer::export(reduce_big, "data/chr17consvIntervals.bed", format = "BED")
```


How many of the 22k+ intervals does this cover?  This is 14Mb out of 83Mb on chr17. 

```{r, echo=FALSE}
f0 <- findOverlaps(commonRegions,reduce_big)

pp <- length(unique(queryHits(f0)))/length(commonRegions)
```

`r length(unique(queryHits(f0)))` intervals (`r round(pp*100,2)` \%).

```{r sI}
sessionInfo()
```

