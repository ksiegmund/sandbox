---
title: "DNA methylation profiles"
author: "ks"
date: "2024-11-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, message=FALSE}
library(GenomicRanges)
library(data.table)
library(ggplot2)
library(rtracklayer)
samplename <- c("JN","IN")
```

# Summarize data for matched samples: `r samplename`

First, read in the data for samples.

```{r data-dir}
readdir <- c("~kims/Google Drive/My Drive/Data/hpc-archive/wg_bed/wg_bed5963")
#readdir <- c("/Volumes/extreme ssd/Data/hpc-archive/wg_bed/wg_bed5963")
```


```{r read-beta-values, echo=FALSE}
fin1 <- fread(file.path(readdir,"wg_s1c.bed"))
fin1$sample <- samplename[1]

fin2 <- fread(file.path(readdir,"wg_s4c.bed"))
fin2$sample <- samplename[2]

combined_fin <- rbindlist(list(fin1, fin2))
setnames(combined_fin, c("chr","start","end","beta","depth","m","u","sample"))
rm(fin1,fin2)

combined_fin[, .(n_CpG = .N, 
              avg_beta = mean(beta), 
           median_beta = median(beta),
             avg_depth = mean(depth),
             max_depth = max(depth),
           frac_depth5 = mean(depth>4)), by = sample]
```

Notice the high maximum read depth.  This reminds me there are regions of the genome that should be excluded due to artifacts.  Let's go find the list from ENCODE.

## Remove Exclusion list regions
Here's how ChatGPT tells me to filter these regions:

```{r get-list}
# Load the exclusion list file (for hg38, as an example)
# starting here https://github.com/Boyle-Lab/Blacklist?tab=readme-ov-file takes me
# https://www.encodeproject.org/annotations/ENCSR636HFF/
# and download https://www.encodeproject.org/files/ENCFF356LFX/
excludelist <- import("data/ENCFF356LFX.bed")
```

Remove regions.

```{r make-GRobject}
betavals <- GRanges(seqnames = combined_fin$chr,
                   IRanges(start = combined_fin$start,width=1))
values(betavals) <- DataFrame(beta = combined_fin$beta,
                             depth = combined_fin$depth,
                                 m = combined_fin$m,
                                 u = combined_fin$u,
                            sample = combined_fin$sample)

filtered_data <- subsetByOverlaps(betavals, excludelist, invert = TRUE)
excluded_data <- subsetByOverlaps(betavals, excludelist)
```


Now summarize the remaining data.
```{r make-Dt}
Dt <- as.data.table(values(filtered_data))
Dt[, .(n_CpG = .N, 
           avg_beta = mean(beta), 
        median_beta = median(beta),
          avg_depth = mean(depth),
       median_depth = as.numeric(median(depth)),
          max_depth = max(depth),
       frac_depth5 = mean(depth>4)), by = sample]
```
How does this compare to the excluded data?
```{r sum-excluded-data}
Dt <- as.data.table(values(excluded_data))
Dt[, .(n_CpG = .N, 
           avg_beta = mean(beta), 
        median_beta = median(beta),
          avg_depth = mean(depth),
       median_depth = median(depth),
          max_depth = max(depth)), by = sample]
```

`r round(length(excluded_data)/length(betavals)*100,1)`$\%$ of measures were excluded.
That was a principled way to remove some high read depths, but it didn't get them all.


```{r save}
fn <- paste0("data/filtered_samples",samplename[1],samplename[2],".rds")
saveRDS(filtered_data,file=fn)
```

## Characterize the data

Do this for sample `r samplename[1]`. The tumor data appear even more variable with respect to sequencing depth across the genome.  I will remove the high read depths before studying the relationship between beta and depth. Run regressions for sample `r samplename[1]`.

```{r lmfit-beta-filtered}
summary(lm(beta ~ depth,data=filtered_data, subset = sample == samplename[1]))$coef
```

They are negatively correlated.  But, beta is a function of depth. Hmmm. That alone makes them correlated. (recall: BMI is correlated with height) 

There's a negative correlation between m and u. (NOTE: if I do not remember to use the exclude list, my high read depths are very influential and I get a positive correlation!)

```{r lmfit-m}
summary(lm(m ~ u, data=combined_fin, subset = sample==samplename[1]))$coef
```

```{r lmfit-m-filtered}
summary(lm(m ~ u, data=filtered_data, subset = sample==samplename[1]))$coef
```

```{r lmfit-m-depth-cutoff}
summary(lm(m ~ u, data=filtered_data, subset = sample ==samplename[1] & depth < 200))$coef
```
Even stronger effect when filtering depth $<$ 200.  But this relies on an arbitrary cutoff so we do not exclude them from the saved data set.


```{r sI}
sessionInfo()
```

